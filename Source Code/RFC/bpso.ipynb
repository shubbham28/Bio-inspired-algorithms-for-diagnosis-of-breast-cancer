{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random,math,copy,timeit\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy as dc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(n,dim):\n",
    "    gens=[[0 for g in range(dim)] for _ in range(n)]\n",
    "    for i,gen in enumerate(gens) :\n",
    "        r=random.randint(1,dim)\n",
    "        for _r in range(r):\n",
    "            gen[_r]=1\n",
    "        random.shuffle(gen)\n",
    "    return gens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_d,train_l,gen):\n",
    "        mask=np.array(gen) > 0\n",
    "        al_data=np.array([al[mask] for al in train_d])\n",
    "        kf = ms.KFold(n_splits=4)\n",
    "        s = 0\n",
    "        for tr_ix,te_ix in kf.split(al_data):\n",
    "            s+= RandomForestClassifier(n_estimators=25).fit(al_data[tr_ix],train_l[tr_ix]).score(al_data[te_ix],train_l[te_ix])#.predict(al_test_data)\n",
    "        s/=4\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsig(n): return 1 / (1 + math.exp(-n))\n",
    "def sign(x): return 1 if x > 0 else (-1 if x!=0 else 0)\n",
    "\n",
    "def BPSO(train_d,train_l,n=20,max_iter=200,w1=0.5,c1=0.5,c2=0.5,vmax=4):\n",
    "    \"\"\"\n",
    "    input:{ \n",
    "            Eval_Func: Evaluate_Function, type is class\n",
    "            n: Number of population, default=20\n",
    "            max_iter: Number of max iteration, default=300\n",
    "            dim: Number of feature, default=None\n",
    "            prog: Do you want to use a progress bar?, default=False\n",
    "            w1: move rate, default=0.5\n",
    "            c1,c2: It's are two fixed variables, default=1,1\n",
    "            vmax: Limit search range of vmax, default=4\n",
    "            }\n",
    "    output:{\n",
    "            Best position: type list(int) [1,0,0,1,.....]\n",
    "            Nunber of 1s in best position: type int [0,1,1,0,1] â†’ 3\n",
    "            }\n",
    "    \"\"\"\n",
    "    dim=len(train_d[0])\n",
    "    personal_best=float(\"-inf\")\n",
    "    global_best=float(\"-inf\")\n",
    "    gens=random_search(n,dim)\n",
    "    vel=[[random.random()-0.5 for d in range(dim)] for _n in range(n)]\n",
    "    one_vel=[[random.random()-0.5 for d in range(dim)] for _n in range(n)]\n",
    "    zero_vel=[[random.random()-0.5 for d in range(dim)] for _n in range(n)]\n",
    "    fit=[float(\"-inf\") for i in range(n)]\n",
    "    personal_best=dc(fit)\n",
    "    xpersonal_best=dc(gens)\n",
    "    global_best=max(fit)\n",
    "    xglobal_best=gens[fit.index(max(fit))]\n",
    "    gens_dict={tuple([0]*dim):float(\"-inf\")}\n",
    "    for it in range(max_iter):\n",
    "        for i in range(n):\n",
    "            if tuple(gens[i]) in gens_dict:\n",
    "                score=gens_dict[tuple(gens[i])]\n",
    "            else:\n",
    "                score=evaluate(train_d,train_l,gens[i])\n",
    "                gens_dict[tuple(gens[i])]=score\n",
    "            fit[i]=score\n",
    "            if fit[i]>personal_best[i]:#max\n",
    "                personal_best[i]=dc(fit[i])\n",
    "                xpersonal_best[i]=dc(gens[i])\n",
    "        gg=max(fit)\n",
    "        xgg=gens[fit.index(gg)]\n",
    "        if global_best<gg:#max\n",
    "            global_best=dc(gg)\n",
    "            xglobal_best=dc(xgg)\n",
    "        oneadd=[[0 for d in range(dim)] for i in range(n)]\n",
    "        zeroadd=[[0 for d in range(dim)] for i in range(n)]\n",
    "        c3=c1*random.random()\n",
    "        dd3=c2*random.random()\n",
    "        for i in range(n):\n",
    "            for j in range(dim):\n",
    "                if xpersonal_best[i][j]==0:\n",
    "                    oneadd[i][j]=oneadd[i][j]-c3\n",
    "                    zeroadd[i][j]=zeroadd[i][j]+c3\n",
    "                else:\n",
    "                    oneadd[i][j]=oneadd[i][j]+c3\n",
    "                    zeroadd[i][j]=zeroadd[i][j]-c3\n",
    "                if xglobal_best[j]==0:\n",
    "                    oneadd[i][j]=oneadd[i][j]-dd3\n",
    "                    zeroadd[i][j]=zeroadd[i][j]+dd3\n",
    "                else:\n",
    "                    oneadd[i][j]=oneadd[i][j]+dd3\n",
    "                    zeroadd[i][j]=zeroadd[i][j]-dd3\n",
    "        one_vel=[[w1*_v+_a for _v,_a in zip(ov,oa)] for ov,oa in zip(one_vel,oneadd)]\n",
    "        zero_vel=[[w1*_v+_a for _v,_a in zip(ov,oa)] for ov,oa in zip(zero_vel,zeroadd)]\n",
    "        for i in range(n):\n",
    "            for j in range(dim):\n",
    "                if abs(vel[i][j]) > vmax:\n",
    "                    zero_vel[i][j]=vmax*sign(zero_vel[i][j])\n",
    "                    one_vel[i][j]=vmax*sign(one_vel[i][j])\n",
    "        for i in range(n):\n",
    "            for j in range(dim):\n",
    "                if gens[i][j]==1:\n",
    "                    vel[i][j]=zero_vel[i][j]\n",
    "                else:\n",
    "                    vel[i][j]=one_vel[i][j]\n",
    "        veln=[[logsig(s[_s]) for _s in range(len(s))] for s in vel]\n",
    "        temp=[[random.random() for d in range(dim)] for _n in range(n)]\n",
    "        for i in range(n):\n",
    "            for j in range(dim):\n",
    "                if temp[i][j]<veln[i][j]:\n",
    "                    gens[i][j]= 0 if gens[i][j] ==1 else 1\n",
    "                else:\n",
    "                    pass\n",
    "    return xglobal_best,xglobal_best.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(gen,tr_x,tr_y,te_x,te_y):\n",
    "    mask=np.array(gen) == 1\n",
    "    al_data=np.array(tr_x[:,mask])\n",
    "    al_test_data=np.array(te_x[:,mask])\n",
    "    return np.mean([RandomForestClassifier(n_estimators=25).fit(al_data,tr_y).score(al_test_data,te_y) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/shubbham28/Downloads/bc/wdbc1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ec5567dce100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/shubbham28/Downloads/bc/wdbc1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/shubbham28/Downloads/bc/wdbc2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlab_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/shubbham28/Downloads/bc/wdbc1.csv'"
     ]
    }
   ],
   "source": [
    "with open(\"/home/shubbham28/Downloads/bc/wdbc1.csv\") as f:\n",
    "    x=np.array([[float(d) for d  in data.split(',')] for data in f.read().splitlines()])\n",
    "with open(\"/home/shubbham28/Downloads/bc/wdbc2.csv\") as f:\n",
    "    y=np.array([float(data) for data in f.read().splitlines()])\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y)\n",
    "train_d, test_d, train_l, test_l = train_test_split(x, training_scores_encoded, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9608391608391609\n",
      "1  010011001101000001000001100101  11  0.962238\n",
      "2  110011100111011010111101101000  18  0.959441\n",
      "3  010010110001110100111110001100  15  0.959441\n",
      "4  010010000110000101011100101100  12  0.969231\n",
      "5  010000010000101100111101101010  13  0.970629\n",
      "6  110110101000100010010111001100  14  0.969231\n",
      "7  010100010111000001001101111011  15  0.965035\n",
      "8  010010001001011111010101000101  14  0.974825\n",
      "9  000111100001000101001101000111  13  0.963636\n",
      "10  000010011110011111010101111011  18  0.953846\n",
      "11  011011001111100011001101001111  18  0.956643\n",
      "12  010010001100111010011100101100  14  0.966434\n",
      "13  010000000001010011010101100100  10  0.969231\n",
      "14  110000100101110001100101000110  13  0.963636\n",
      "15  010000000001100110011000100111  11  0.965035\n",
      "16  010000010000011011001100100011  11  0.965035\n",
      "17  110010010000010110010111100000  12  0.962238\n",
      "18  010010000100010110111101011110  15  0.967832\n",
      "19  010110011111000001111100001010  15  0.960839\n",
      "20  010010000101011010010101101111  15  0.966434\n",
      "Final:   010010000101000011011101101100   13   0.964545    23304.5369\n"
     ]
    }
   ],
   "source": [
    "k=[1 for r in range(len(x[0]))]\n",
    "print test_score(k,train_d,train_l,test_d,test_l)\n",
    "fattr=0\n",
    "ftest=0.0\n",
    "flist=[0 for r in range(len(x[0]))]\n",
    "final_list=[0 for r in range(len(x[0]))]\n",
    "start=timeit.default_timer()\n",
    "for i in range(20):\n",
    "    g,l=BPSO(train_d,train_l,n=20,max_iter=200,w1=0.5,c1=0.5,c2=0.5,vmax=4)\n",
    "    fattr+=l\n",
    "    test=test_score(g,train_d,train_l,test_d,test_l)\n",
    "    ftest+=test\n",
    "    for j in range(len(flist)):\n",
    "        if g[j]==1:\n",
    "            flist[j]+=1\n",
    "    print(\"{0}  {1}  {2}  {3:.6f}\".format(i+1,\"\".join(map(str,g)),l,test))\n",
    "fattr=fattr/20\n",
    "ftest=ftest/20\n",
    "end=timeit.default_timer()\n",
    "time=end-start\n",
    "final=np.argsort(flist)[::-1][:fattr]\n",
    "for i in range(len(final)):\n",
    "    final_list[final[i]]=1\n",
    "print(\"{0}  {1}   {2}   {3:.6f}    {4:.4f}\".format(\"Final: \",\"\".join(map(str,final_list)),fattr,ftest,time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/shubbham28/Downloads/Arrhythmia/heart.csv\") as f:\n",
    "    x=np.array([[float(d) for d  in data.split(',')] for data in f.read().splitlines()])\n",
    "with open(\"/home/shubbham28/Downloads/Arrhythmia/heart_output.csv\") as f:\n",
    "    y=np.array([float(data) for data in f.read().splitlines()])\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y)\n",
    "train_d, test_d, train_l, test_l = train_test_split(x, training_scores_encoded, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8323529411764706\n",
      "1  0111001111111  10  0.844118\n",
      "2  1111101111011  11  0.811765\n",
      "3  1110110111111  11  0.814706\n",
      "4  1110110011111  10  0.817647\n",
      "5  0011100100011  6  0.811765\n",
      "6  0111110100011  8  0.820588\n",
      "7  0111111011110  10  0.808824\n",
      "8  1111000010111  8  0.826471\n",
      "9  0111110011011  9  0.797059\n",
      "10  0110101101011  8  0.823529\n",
      "11  1111011111111  12  0.838235\n",
      "12  0101111010110  8  0.785294\n",
      "13  0110110111011  9  0.776471\n",
      "14  1101111010111  10  0.791176\n",
      "15  1110010011011  8  0.811765\n",
      "16  0110111101111  10  0.820588\n",
      "17  1111110011110  10  0.811765\n",
      "18  0110111110110  9  0.811765\n",
      "19  0110111110011  9  0.808824\n",
      "20  1111000111011  9  0.817647\n",
      "[9, 19, 18, 12, 15, 14, 10, 12, 16, 13, 11, 20, 16] 9\n",
      "[11  1  2 12  8  4  5  9  7]\n",
      "Final:   0110110111011   9   0.812500    8765.1357\n"
     ]
    }
   ],
   "source": [
    "k=[1 for r in range(len(x[0]))]\n",
    "print test_score(k,train_d,train_l,test_d,test_l)\n",
    "fattr=0\n",
    "ftest=0.0\n",
    "flist=[0 for r in range(len(x[0]))]\n",
    "final_list=[0 for r in range(len(x[0]))]\n",
    "start=timeit.default_timer()\n",
    "for i in range(20):\n",
    "    g,l=BPSO(train_d,train_l,n=20,max_iter=200,w1=0.5,c1=0.5,c2=0.5,vmax=4)\n",
    "    fattr+=l\n",
    "    test=test_score(g,train_d,train_l,test_d,test_l)\n",
    "    ftest+=test\n",
    "    for j in range(len(flist)):\n",
    "        if g[j]==1:\n",
    "            flist[j]+=1\n",
    "    print(\"{0}  {1}  {2}  {3:.6f}\".format(i+1,\"\".join(map(str,g)),l,test))\n",
    "fattr=fattr/20\n",
    "ftest=ftest/20\n",
    "end=timeit.default_timer()\n",
    "time=end-start\n",
    "print flist,fattr\n",
    "final=np.argsort(flist)[::-1][:fattr]\n",
    "print final\n",
    "for i in range(len(final)):\n",
    "    final_list[final[i]]=1\n",
    "print(\"{0}  {1}   {2}   {3:.6f}    {4:.4f}\".format(\"Final: \",\"\".join(map(str,final_list)),fattr,ftest,time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
