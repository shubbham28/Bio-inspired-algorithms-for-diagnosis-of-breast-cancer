{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random,timeit\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy as dc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(n,dim):\n",
    "    gens=[[0 if g != j else 1 for g in range(n)] for j in range(dim)]\n",
    "    return gens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_d,train_l,gen):\n",
    "        mask=np.array(gen) > 0\n",
    "        al_data=np.array([al[mask] for al in train_d])\n",
    "        kf = ms.KFold(n_splits=4)\n",
    "        s = 0\n",
    "        for tr_ix,te_ix in kf.split(al_data):\n",
    "            s+= RandomForestClassifier(n_estimators=25).fit(al_data[tr_ix],train_l[tr_ix]).score(al_data[te_ix],train_l[te_ix])#.predict(al_test_data)\n",
    "        s/=4\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bees_optimization(bee,binary,i):\n",
    "    binary=list(binary)\n",
    "    j=random.randint(0,len(binary)-1)\n",
    "    k=random.randint(0,len(binary)-1)\n",
    "    while k==i:\n",
    "        k=random.randint(0,len(binary)-1)\n",
    "    fit=binary[j]+random.uniform(-1,1)*(binary[j]-binary[k])\n",
    "    for x in range(bee):\n",
    "        y=random.randint(0,len(binary)-1)\n",
    "        while y==i:\n",
    "            y=random.randint(0,len(binary)-1)\n",
    "        r=random.uniform(0,1)\n",
    "        if r<=fit:\n",
    "            binary[y]=1\n",
    "        \n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BABCO(train_d,train_l,n=10,max_iter=25,employee_percent=0.5,max_limit=5):\n",
    "    \"\"\"\n",
    "    input:{ Eval_Func: Evaluate_Function, type is class\n",
    "            n: Number of population, default=20\n",
    "            max_iter: Number of max iteration, default=300\n",
    "            }\n",
    "    output:{\n",
    "            Best position: type list(int) [1,0,0,1,.....]\n",
    "            Nunber of 1s in best position: type int [0,1,1,0,1] â†’ 3\n",
    "            }\n",
    "    \"\"\"\n",
    "    employed_bees = int(round(n*employee_percent))\n",
    "    onlooker_bees = n - employed_bees       \n",
    "\n",
    "    dim=len(train_d[0])\n",
    "    global_best=float(\"-inf\")\n",
    "    global_position=tuple([0]*dim)\n",
    "    gens_dict = {}\n",
    "    limit=[0]*dim\n",
    "    gens=random_search(dim,dim)\n",
    "    for gen in gens:\n",
    "        if tuple(gen) in gens_dict:\n",
    "            score = gens_dict[tuple(gen)]\n",
    "        else:\n",
    "            score=evaluate(train_d,train_l,gen)\n",
    "            gens_dict[tuple(gen)]=score\n",
    "        if score > global_best:\n",
    "            global_best=score\n",
    "            global_position=dc(gen)\n",
    "            \n",
    "            \n",
    "    for it in range(max_iter):\n",
    "        for i in range(employed_bees):\n",
    "            for i,x in enumerate(gens):\n",
    "                gen=bees_optimization(employed_bees,x,i)\n",
    "                if tuple(gen) in gens_dict:\n",
    "                    score = gens_dict[tuple(gen)]\n",
    "                else:\n",
    "                    score=evaluate(train_d,train_l,gen)\n",
    "                    gens_dict[tuple(gen)]=score\n",
    "\n",
    "                if score > gens_dict[tuple(gens[i])]:\n",
    "                    limit[i]=0\n",
    "                    gens[i]= gen\n",
    "                else:\n",
    "                    limit[i]+=1\n",
    "\n",
    "                if score > global_best:\n",
    "                    global_best=score\n",
    "                    global_position=dc(gen)\n",
    "\n",
    "                if limit[i]>=max_limit:\n",
    "                    gens[i]=[0 if g != i else 1 for g in range(dim)]\n",
    "    \n",
    "        for i in range(onlooker_bees):\n",
    "            for i,x in enumerate(gens):\n",
    "                gen=bees_optimization(employed_bees,x,i)\n",
    "                if tuple(gen) in gens_dict:\n",
    "                    score = gens_dict[tuple(gen)]\n",
    "                else:\n",
    "                    score=evaluate(train_d,train_l,gen)\n",
    "                    gens_dict[tuple(gen)]=score\n",
    "\n",
    "                if score > gens_dict[tuple(gens[i])]:\n",
    "                    limit[i]=0\n",
    "                    gens[i]= gen\n",
    "                else:\n",
    "                    limit[i]+=1\n",
    "\n",
    "                if score > global_best:\n",
    "                    global_best=score\n",
    "                    global_position=dc(gen)\n",
    "\n",
    "                if limit[i]>=max_limit:\n",
    "                    gens[i]=[0 if g != i else 1 for g in range(dim)]\n",
    "\n",
    "                \n",
    "    return global_position,global_position.count(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(gen,tr_x,tr_y,te_x,te_y):\n",
    "    mask=np.array(gen) == 1\n",
    "    al_data=np.array(tr_x[:,mask])\n",
    "    al_test_data=np.array(te_x[:,mask])\n",
    "    return np.mean([RandomForestClassifier(n_estimators=25).fit(al_data,tr_y).score(al_test_data,te_y) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/shubbham28/Downloads/bc/wdbc1.csv\") as f:\n",
    "    x=np.array([[float(d) for d  in data.split(',')] for data in f.read().splitlines()])\n",
    "with open(\"/home/shubbham28/Downloads/bc/wdbc2.csv\") as f:\n",
    "    y=np.array([float(data) for data in f.read().splitlines()])\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y)\n",
    "train_d, test_d, train_l, test_l = train_test_split(x, training_scores_encoded, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9622377622377621\n",
      "1  010011010100100001010111101011  15  0.966434\n",
      "2  111101111010111100100101001011  19  0.959441\n",
      "3  111001111111110000100111011011  20  0.960839\n",
      "4  110000001011000110100001101011  13  0.962238\n",
      "5  011100011111001000110110111000  16  0.967832\n",
      "6  110110111011110011110101111010  21  0.973427\n",
      "7  011011001101010011100001111111  18  0.972028\n",
      "8  110010011111110110110101001010  18  0.958042\n",
      "9  110011011111000000000010101101  14  0.965035\n",
      "10  011110010000010000000100001110  10  0.962238\n",
      "11  011100011000010101001000001000  10  0.962238\n",
      "12  110000111111111100010101000011  17  0.960839\n",
      "13  010011110000010110111100011110  16  0.977622\n",
      "14  010011010000010000001101001000  9  0.959441\n",
      "15  010010000100000000100101110000  8  0.976224\n",
      "16  101011000101101000000101111010  14  0.965035\n",
      "17  010110010010010111000101101001  14  0.963636\n",
      "18  010010101010000110001101001111  14  0.979021\n",
      "19  010111011011101010010001001000  14  0.948252\n",
      "20  010100010100111011010101100010  14  0.960839\n",
      "Final:   010010011111110000000101101010   14   0.965035    4902.5178\n"
     ]
    }
   ],
   "source": [
    "k=[1 for r in range(len(x[0]))]\n",
    "print test_score(k,train_d,train_l,test_d,test_l)\n",
    "fattr=0\n",
    "ftest=0.0\n",
    "flist=[0 for r in range(len(x[0]))]\n",
    "final_list=[0 for r in range(len(x[0]))]\n",
    "start=timeit.default_timer()\n",
    "for i in range(20):\n",
    "    g,l=BABCO(train_d,train_l,n=10,max_iter=25,employee_percent=0.5,max_limit=5)\n",
    "    fattr+=l\n",
    "    test=test_score(g,train_d,train_l,test_d,test_l)\n",
    "    ftest+=test\n",
    "    for j in range(len(flist)):\n",
    "        if g[j]==1:\n",
    "            flist[j]+=1\n",
    "    print(\"{0}  {1}  {2}  {3:.6f}\".format(i+1,\"\".join(map(str,g)),l,test))\n",
    "fattr=fattr/20\n",
    "ftest=ftest/20\n",
    "end=timeit.default_timer()\n",
    "time=end-start\n",
    "final=np.argsort(flist)[::-1][:fattr]\n",
    "for i in range(len(final)):\n",
    "    final_list[final[i]]=1\n",
    "print(\"{0}  {1}   {2}   {3:.6f}    {4:.4f}\".format(\"Final: \",\"\".join(map(str,final_list)),fattr,ftest,time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/shubbham28/Downloads/Arrhythmia/heart.csv\") as f:\n",
    "    x=np.array([[float(d) for d  in data.split(',')] for data in f.read().splitlines()])\n",
    "with open(\"/home/shubbham28/Downloads/Arrhythmia/heart_output.csv\") as f:\n",
    "    y=np.array([float(data) for data in f.read().splitlines()])\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y)\n",
    "train_d, test_d, train_l, test_l = train_test_split(x, training_scores_encoded, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7999999999999998\n",
      "1  1111111111111  13  0.802941\n",
      "2  1111010000111  8  0.841176\n",
      "3  1011110010110  8  0.755882\n",
      "4  1111111010111  11  0.838235\n",
      "5  1111010011111  10  0.805882\n",
      "6  0111011011110  9  0.767647\n",
      "7  1110010010111  8  0.832353\n",
      "8  1110011010110  8  0.808824\n",
      "9  1111011110111  11  0.797059\n",
      "10  1110011111111  11  0.817647\n",
      "11  1111111010110  10  0.791176\n",
      "12  1111001110111  10  0.817647\n",
      "13  1111011011110  10  0.750000\n",
      "14  1011111110111  11  0.788235\n",
      "15  1110010111111  10  0.788235\n",
      "16  1111011110111  11  0.826471\n",
      "17  1110111011110  10  0.758824\n",
      "18  1111011111111  12  0.814706\n",
      "19  1111101110111  11  0.826471\n",
      "20  1111011111110  11  0.770588\n",
      "[19, 18, 20, 15, 7, 18, 15, 10, 19, 9, 20, 20, 13] 10\n",
      "[11 10  2  8  0  5  1  6  3 12]\n",
      "Final:   1111011010111   10   0.800000    2338.7517\n"
     ]
    }
   ],
   "source": [
    "k=[1 for r in range(len(x[0]))]\n",
    "print test_score(k,train_d,train_l,test_d,test_l)\n",
    "fattr=0\n",
    "ftest=0.0\n",
    "flist=[0 for r in range(len(x[0]))]\n",
    "final_list=[0 for r in range(len(x[0]))]\n",
    "start=timeit.default_timer()\n",
    "for i in range(20):\n",
    "    g,l=BABCO(train_d,train_l,n=10,max_iter=25,employee_percent=0.5,max_limit=5)\n",
    "    fattr+=l\n",
    "    test=test_score(g,train_d,train_l,test_d,test_l)\n",
    "    ftest+=test\n",
    "    for j in range(len(flist)):\n",
    "        if g[j]==1:\n",
    "            flist[j]+=1\n",
    "    print(\"{0}  {1}  {2}  {3:.6f}\".format(i+1,\"\".join(map(str,g)),l,test))\n",
    "fattr=fattr/20\n",
    "ftest=ftest/20\n",
    "end=timeit.default_timer()\n",
    "time=end-start\n",
    "print flist,fattr\n",
    "final=np.argsort(flist)[::-1][:fattr]\n",
    "print final\n",
    "for i in range(len(final)):\n",
    "    final_list[final[i]]=1\n",
    "print(\"{0}  {1}   {2}   {3:.6f}    {4:.4f}\".format(\"Final: \",\"\".join(map(str,final_list)),fattr,ftest,time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
